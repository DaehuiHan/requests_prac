# requests를 이용한 웹 스크랩핑 (크롤링) 연습

- 코롤링 이란?

  1. 특정 페이지에 있는 정보들을 내가 원하는 포맷으로 가져오는것
  2. WebScrapping을 자동으로 돌아다니며 분석 및 저장등을 하는 행위 정도로 저장할수 있습니다.

- HTTP 매서드

  - GET: 리소스 요청 (크롤링에 주로 사용) => 받아드리는 녀석
  - POST: 대기 리소스 추가 요청이나 수정/삭제 목적으로 사용(크롤링에 주로 사용) => 내가 추가로 요청하는 녀석
  - PUT: 리소스 수정 요청
  - DELETE: 리소스 삭제 요청
    <!-- - HEAD: HTTP헤더 정보만 요청. 해당 자원의 존재여부를 확인하기 위한 목적 -->
    <!-- - OPTIONS: 웹서버가 지원하는 매서드 종류 반환 요청 -->
    <!-- - TRACE: 클라이언트의 요청을 그대로 반환 (여기서 클라이언트느 사용자를 말하겠죠?) -->

- 크롤링이 가능한 이유

  - 브라우져에 나와있는 페이지는 이미 내가 가지고 온 것이다.
  - 거기서 내가 필요한 정보를 속아내는 것이다.

- 크롤링에서 중요한 것은

  1. 브라우저를 켜지 않고 코드단에서 요청하는 것.
  2. 해당 페이지의 html 정보중에 내가 원하는 정보를 잘 속아내는 것

- 요청하기를 위한 패키지 = requests
- 속아내기를 위한 패키지 = bs4
